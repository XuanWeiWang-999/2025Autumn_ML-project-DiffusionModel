{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50f0f3a",
   "metadata": {},
   "source": [
    "# Two Normal Dist. test for Diffusion Model in 1D\n",
    "測試：生成兩種不同的Nomal distribution N(5,2),加噪去噪以後還會變成原來的兩個不同分布\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187aeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "import math, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from collections import deque\n",
    "\n",
    "DEVICE        = 'cpu' \n",
    "T             = 500        # diffusion steps\n",
    "BATCH_SIZE    = 512\n",
    "TRAIN_ITERS   = 2000       # 訓練步數\n",
    "LR            = 5e-4\n",
    "HIDDEN        = 512\n",
    "TIME_DIM      = 64\n",
    "N_TRAIN_SAMP  = 10000       # 訓練資料量）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b553070",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants setting\n",
    "betas = torch.linspace(1e-4, 0.02, T+1, device=DEVICE)\n",
    "alphas = 1.0-betas\n",
    "abar = torch.cumprod(alphas, dim=0)\n",
    "sqrt_abar = torch.sqrt(abar)\n",
    "sqrt_lmabar = torch.sqrt(1.0-abar)\n",
    "sqrt_rcp_a = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "### 這塊留給 time embedding\n",
    "#-------------------------\n",
    "def sinusoidal_time_emb(t, dim):\n",
    "    # t: (B,) 的整數 timestep\n",
    "    device = t.device\n",
    "    t = t.float().unsqueeze(1)  # (B,1)\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        torch.arange(half, device=device).float() * (-math.log(10000.0) / max(1, half-1))\n",
    "    )  # (half,)\n",
    "    angles = t * freqs  # (B,half)\n",
    "    emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=1)  # (B, 2*half)\n",
    "    if dim % 2 == 1:  # 補一維避免奇數維崩\n",
    "        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n",
    "    return emb  # (B, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a9d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建nn\n",
    "class EpsMLP(nn.Module):\n",
    "    def __init__(self, hidden=HIDDEN, time_dim=TIME_DIM):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        # 把 time embedding 投影到hidden layer\n",
    "        self.t_proj = nn.Sequential(\n",
    "            nn.Linear(time_dim, hidden), \n",
    "            nn.SiLU()\n",
    "            )\n",
    "        \n",
    "        # y_t(1維) + time(hidden) → hidden → 1維噪聲預測\n",
    "        in_dim = hidden + 1 # y+dim=1\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden,1)\n",
    "        )\n",
    "    def forward(self, y_t, t):\n",
    "        t_emb = sinusoidal_time_emb(t, self.time_dim)   # (B, time_dim)\n",
    "        h_t = self.t_proj(t_emb)                        # (B, hidden)\n",
    "        h = torch.cat([y_t, h_t], dim=1)                # (B, 1+hidden)\n",
    "        return self.net(h)\n",
    "\n",
    "model = EpsMLP().to(DEVICE)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=TRAIN_ITERS, eta_min=1e-5)  ###<---10/1新增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394f0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 計算 y_t= sqrt(abar_t) y0 + sqrt(1-abar_t) * eps\n",
    "# ---------------------\n",
    "def q_sample(y0, t, eps=None):\n",
    "    if eps is None:\n",
    "        eps = torch.randn_like(y0)   ## 產生跟y0大小一樣的初始normal雜訊\n",
    "    sa = sqrt_abar[t].view(-1,1)\n",
    "    som = sqrt_lmabar[t].view(-1,1)\n",
    "    return sa*y0+som*eps, eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1067b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===============================\n",
    "### ALGORITHM 1\n",
    "### ===============================\n",
    "\n",
    "def train_loop(record_step):\n",
    "    model.train()\n",
    "    losses =[]\n",
    "    movavg =[]\n",
    "    ma=deque(maxlen=50) #長度為50的mov_avg frame\n",
    "\n",
    "    for step in range(1, TRAIN_ITERS+1):\n",
    "        # 取 y0~N(0,1)\n",
    "        y0 = torch.randn(BATCH_SIZE, 1, device=DEVICE)\n",
    "        # 隨機time step\n",
    "        t = torch.randint(2,T+1, (BATCH_SIZE,),device=DEVICE).long()\n",
    "        # 向前加噪\n",
    "        y_t, eps = q_sample(y0,t)\n",
    "        # 預測噪音\n",
    "        eps_hat = model(y_t, t)     \n",
    "        loss = F.mse_loss(eps_hat, eps)\n",
    "\n",
    "        opt.zero_grad(set_to_none = True) \n",
    "        loss.backward()\n",
    "        #把L2norm限制在1.0以內避免梯度爆炸 ; 但如果loss穩定可以不用\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "\n",
    "        if step % record_step ==0: \n",
    "            val = loss.detach().item()\n",
    "            losses.append(val)\n",
    "            ma.append(val)\n",
    "            movavg.append(sum(ma)/len(ma))\n",
    "            print(f\"[train] step {step:4d} | loss {loss.item():.6f}\")\n",
    "    \n",
    "    \n",
    "    return losses, movavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d15481",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===============================\n",
    "### ALGORITHM 2\n",
    "### ===============================\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_on_grid(n_points = 401):\n",
    "    model.eval()\n",
    "    # 初始化 y 的 batch，要用 n_points\n",
    "    y = torch.randn(n_points, 1, device=DEVICE)  ## 直接在N(0,1)裡面抽東西就好\n",
    "    for t in reversed(range(T+1)):\n",
    "        tb = torch.full((n_points,), t, device=DEVICE, dtype=torch.long)\n",
    "        eps_hat = model(y, tb)  ###<<<---已拿掉x\n",
    "        mean = sqrt_rcp_a[t]*(y - (betas[t]/sqrt_lmabar[t]) * eps_hat) #那行公式\n",
    "        if t>0:\n",
    "            y = mean + torch.sqrt(betas[t])*torch.randn_like(y)\n",
    "        ###<----拿掉else\n",
    "    \n",
    "    return y.squeeze(1).cpu() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f0385",
   "metadata": {},
   "source": [
    "## Test area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa9b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
